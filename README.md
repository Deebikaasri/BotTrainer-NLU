# ğŸ¤– BotTrainer â€“ LLM-Based NLU Model Trainer & Evaluator

BotTrainer is a modern Natural Language Understanding (NLU) framework built using Large Language Models (LLMs) to identify user intents and extract entities through prompt engineering, rather than relying on conventional machine-learning classifiers.

The system is designed around a JSON-centric dataset, runs locally using the Gemma-3 model via Ollama, and offers live predictions, evaluation metrics, and dataset insights through an intuitive Streamlit interface.

ğŸš€ Core Features

ğŸ”¹ Intent recognition powered by LLM reasoning

ğŸ”¹ JSON-based intent and entity definitions

ğŸ”¹ Prompt-driven structured responses

ğŸ”¹ Fully local inference using Gemma-3

ğŸ”¹ Built-in evaluation with performance metrics

ğŸ”¹ Modular, scalable project organization

ğŸ”¹ Interactive dashboard for testing and analysis

ğŸ¯ Project Goals

Eliminate dependency on traditional intent classifiers

Combine intent classification and entity extraction in a single inference step

Ensure LLM outputs follow a strict JSON structure

Measure NLU performance using standard evaluation metrics

Provide an easy-to-use interface for experimentation

Follow industry-standard ML project practices

ğŸ§  System Architecture Overview
User Query
   â†“
Prompt Template + Intent Definitions
   â†“
Gemma-3 LLM (Ollama â€“ Local Execution)
   â†“
Structured JSON Response
   â†“
Intent & Entity Extraction
   â†“
Evaluation Results & UI Display

ğŸ“¦ Dataset Design
1ï¸âƒ£ Core Dataset â€“ intents.json

BotTrainer follows a JSON-first approach, where intent definitions are directly injected into the LLM prompt.

Each intent includes:

Intent label

Example user queries

Associated entity types

Sample Structure
{
  "intents": [
    {
      "name": "book_flight",
      "examples": [
        "Book a flight to Delhi",
        "I want to fly to Mumbai tomorrow"
      ],
      "entities": ["location", "date"]
    }
  ],
  "entities": {
    "location": ["Delhi", "Mumbai", "Chennai"],
    "date": ["today", "tomorrow"]
  }
}


Why JSON-first?

âœ” Directly consumed by the LLM

âœ” No embeddings or vector stores required

âœ” Easy to modify and extend for new domains

2ï¸âƒ£ Evaluation Dataset â€“ full_nlu_dataset_200.csv

A flattened dataset generated from intents.json to support:

Performance evaluation

Metric computation

Dataset visualization

Dataset Columns

Field	Description
text	Input sentence
true_intent	Expected intent
ğŸ§ª Evaluation Methodology

Number of intents: 10

Test samples: One example per intent

Total evaluation inputs: 10

Evaluation Benefits

Ensures equal coverage for all intents

Avoids skew caused by repeated samples

Enables transparent intent-wise validation

Metrics Calculated

Accuracy

Precision (weighted)

Recall (weighted)

F1-Score (weighted)

Confusion Matrix

ğŸ—‚ï¸ Repository Structure
INFOSIS_BOTTRAINER/
â”‚
â”œâ”€â”€ assets/                 # UI screenshots
â”œâ”€â”€ config/                 # Configuration files
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_data/           # Dataset files
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/         # Core logic modules
â”‚   â”œâ”€â”€ pipeline/           # End-to-end workflows
â”‚   â””â”€â”€ utils/              # Utilities & helpers
â”œâ”€â”€ app.py                  # Streamlit app
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

âš™ï¸ Installation & Usage
Install Dependencies
pip install -r requirements.txt

Download Gemma-3 Model
ollama pull gemma3:latest

Launch Application
streamlit run app.py

ğŸ§© Technology Stack

Python

Streamlit

Pandas

Scikit-learn

Ollama

Gemma-3 LLM

Prompt Engineering

ğŸ“ Skills & Learnings

Building LLM-driven NLU pipelines

Designing JSON-centric AI systems

Structured prompt engineering

Evaluating intent classification models

Developing interactive ML dashboards

Managing scalable ML project layouts

ğŸ‘¨â€ğŸ’» Developer
S.Deebikaasri

â­ Planned Improvements

Entity-level performance evaluation

Visual confusion matrix heatmaps

Prompt debugging and inspection tools

Multi-model comparison support

Containerized deployment using Docker
