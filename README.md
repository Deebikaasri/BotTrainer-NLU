# ğŸ¤– BotTrainer â€“ LLM-Based NLU Model Trainer & Evaluator

BotTrainer is an end-to-end **LLM-based Natural Language Understanding (NLU)** system that performs **intent classification** and **entity extraction** using **prompt engineering** instead of traditional machine learning classifiers.

The system follows a **JSON-first design**, uses a **local Gemma-3 model via Ollama**, and provides **evaluation metrics** along with an **interactive Streamlit web interface** for real-time testing.

---

## ğŸ“Œ Project Objectives

* Build an NLU pipeline using **Large Language Models (LLMs)**
* Replace classical ML-based intent classifiers with **prompt-based inference**
* Perform **intent detection** and **entity extraction** in a single step
* Evaluate performance using:

  * Accuracy
  * Precision
  * Recall
  * F1-score
* Provide a **real-time chatbot-style UI** using Streamlit
* Follow a **production-style project structure** suitable for academic and real-world use

---

## ğŸ§  Key Features

* ğŸ“„ **JSON-based intent & entity schema** (`intents.json`)
* ğŸ§© **Prompt engineering** with schema-guided constraints
* ğŸ–¥ï¸ **Local LLM inference** using **Gemma-3** (via Ollama)
* âœ… **Automatic JSON parsing & validation** of LLM output
* ğŸ“Š **Evaluation pipeline** with confusion matrix
* ğŸŒ **Streamlit web interface** for live intent testing

 ğŸ§  System Architecture â€“ BotTrainer
User Input (Text Query)
        â†“
Prompt Template + Intent Schema (JSON-first)
        â†“
Gemma-3 LLM (Local Inference via Ollama)
        â†“
Structured JSON Output (Intent + Entities)
        â†“
Intent & Entity Parsing & Validation
        â†“
Evaluation Engine (Accuracy, Precision, Recall, F1, Confusion Matrix)
        â†“
Streamlit UI Visualization (Predictions, Metrics, Dashboard)

ğŸ“¦ Dataset Design & ğŸ§ª Evaluation Strategy
1ï¸âƒ£ Primary Dataset â€“ intents.json (Core Dataset)

The BotTrainer system follows a JSON-first dataset design, where the LLM directly consumes the intent schema during inference.
No intermediate feature extraction or vector embeddings are used.

Each intent definition contains:

Intent name

Training examples (user utterances)

Supported entity types

ğŸ“Œ Example
{
  "intents": [
    {
      "name": "book_flight",
      "examples": [
        "Book a flight to Delhi",
        "I want to fly to Mumbai tomorrow"
      ],
      "entities": ["location", "date"]
    }
  ],
  "entities": {
    "location": ["Delhi", "Mumbai", "Chennai"],
    "date": ["today", "tomorrow"]
  }
}
2ï¸âƒ£ Flattened Dataset â€“ full_nlu_dataset_200.csv

The flattened dataset is programmatically generated from intents.json and is used for:

Model evaluation

Performance visualization

Dataset analysis

ğŸ“Š Dataset Schema
Column Name	Description
text	User utterance
true_intent	Ground truth intent label

âœ” Enables compatibility with evaluation libraries
âœ” Supports confusion matrix and metric computation

ğŸ§ª Evaluation Strategy

The evaluation approach is designed to fairly validate all intents without bias.

ğŸ”¹ Evaluation Setup

Total Intents: 10

Evaluation Samples: 1 sample per intent

Total Evaluation Size: 10 samples

ğŸ“ˆ Metrics Used

The following standard classification metrics are computed:

Accuracy

Precision (Weighted)

Recall (Weighted)

F1-Score (Weighted)

Confusion Matrix

These metrics provide a comprehensive view of NLU performance, including both overall accuracy and per-intent behavior.

---


## ğŸ“¦ Dataset Design

### Primary Dataset: `intents.json`

The dataset defines:

* Intent names
* Example utterances
* Entity schema per intent

